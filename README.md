# Simple-NN-for-MNIST-Digit-Classification
This project uses a Neural Network (NN) to classify handwritten digits from the MNIST dataset (42,000 images). The model is built with TensorFlow/Keras, normalizes pixel values, and predicts digits (0-9). It includes preprocessing, training, and evaluation steps with accuracy visualization. ğŸš€

---

# ğŸ§  Simple Neural Network for MNIST Digit Classification

This project uses a **Neural Network (NN)** to classify handwritten digits from the **MNIST dataset** (42,000 images). The model is built with **TensorFlow/Keras**, normalizes pixel values, and predicts digits (0â€“9). It includes preprocessing, training, evaluation, and accuracy visualization steps. âœ¨ğŸ“Š

---

## ğŸ“ Project Overview

This project aims to build a **Neural Network (NN)** capable of recognizing handwritten digits from the **MNIST dataset**. Using **TensorFlow/Keras**, the model achieves high accuracy in classifying digits after being trained on 42,000 labeled images. ğŸ–Šï¸ğŸ”

---

## ğŸŒŸ Key Features

- âœ… Preprocessing and normalization of image data
- ğŸ§  Simple **Neural Network (NN)** for classification
- ğŸ‹ï¸ Training and evaluation of the model
- ğŸ“ˆ Accuracy and loss visualization
- ğŸ”® Prediction on new handwritten digits

---

## ğŸ’» Technologies Used

- **Python** ğŸ
- **TensorFlow/Keras** ğŸ§ 
- **NumPy & Pandas** ğŸ“Š
- **Matplotlib & Seaborn** ğŸ“‰

---

## ğŸ“‚ Dataset

The project uses the **MNIST dataset**, which consists of **28x28 grayscale images** of handwritten digits (0â€“9). The dataset contains:

- **42,000 training images**
- **28,000 test images**

ğŸ”— [Dataset Link](https://www.kaggle.com/competitions/digit-recognizer/data)

---

## ğŸš€ Installation & Usage

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-username/mnist-handwritten-digit-recognition.git
cd mnist-handwritten-digit-recognition
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install tensorflow numpy pandas matplotlib seaborn
```

### 3ï¸âƒ£ Run the Model

```python
python train.py
```

---

## ğŸ“Š Dataset Analysis

The dataset comprises **785 columns**:
- The first column (`label`) represents the digit (0â€“9).
- The remaining **784 columns** correspond to pixel values of the 28x28 grayscale image.

Key statistical insights:
- **Count**: 42,000 entries.
- **Mean Pixel Values**: Most pixels have a mean value of 0, with some variability in edge pixels.
- **Standard Deviation**: Highlights variation in pixel intensity across images.
- **Min/Max Values**: Pixel values range from 0 to 254.

Example of the dataset structure:

| label | pixel0 | pixel1 | ... | pixel783 |
|-------|--------|--------|-----|----------|
| 1     | 0      | 0      | ... | 0        |
| 0     | 0      | 0      | ... | 0        |

---

## ğŸ§© Model Architecture

The Neural Network consists of the following layers:

- **Dense Layer 1**: Output Shape = `(None, 128)`, Parameters = 100,480
- **Dense Layer 2**: Output Shape = `(None, 64)`, Parameters = 8,256
- **Dense Layer 3 (Output Layer)**: Output Shape = `(None, 10)`, Parameters = 650

**Total Parameters**: 109,386  
**Trainable Parameters**: 109,386  
**Non-Trainable Parameters**: 0

---

## ğŸ“ˆ Training Results

The model was trained for **10 epochs** with the following performance metrics:

| Epoch | Training Loss | Training Accuracy | Validation Loss | Validation Accuracy |
|-------|---------------|-------------------|-----------------|---------------------|
| 1     | 0.3007        | 0.9139            | 0.1618          | 0.9526              |
| 2     | 0.1262        | 0.9629            | 0.1539          | 0.9495              |
| ...   | ...           | ...               | ...             | ...                 |
| 10    | 0.0184        | 0.9937            | 0.1352          | 0.9681              |

**Final Validation Accuracy**: **96.81%** ğŸ‰

---

## ğŸ¯ Model Evaluation

- **Normalization**: Pixel values were scaled between 0 and 1 to improve convergence. ğŸ”„
- **Optimizer**: Adam optimizer was used for efficient training. âš¡
- **Loss Function**: Categorical cross-entropy loss was applied to handle multi-class classification. ğŸ“‰
- **Performance Visualization**: Accuracy and loss curves were plotted to monitor training progress. ğŸ“Š

---

## ğŸ”® Prediction Example

The trained model successfully predicted the label of a test image as follows:

- **Predicted Label**: 0 âœ…

---

## ğŸ¤ Contributing

Contributions to this project are welcome! Feel free to **fork** this repository, make improvements, and submit a **pull request**. ğŸš€

---

## ğŸ“œ License

This project is **open-source** and available under a permissive license. ğŸŒ

---

ğŸŒŸ **Follow me for more projects!** ğŸŒŸ

---
